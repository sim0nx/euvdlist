{
  "id": "EUVD-2025-19074",
  "enisaUuid": "d34c5746-c08f-3b87-a579-44990660cca5",
  "description": "llama.cpp is an inference of several LLM models in C/C++. Prior to version b5721, there is a signed vs. unsigned integer overflow in llama.cpp's tokenizer implementation (llama_vocab::tokenize) (src/llama-vocab.cpp:3036) resulting in unintended behavior in tokens copying size comparison. Allowing heap-overflowing llama.cpp inferencing engine with carefully manipulated text input during tokenization process. This issue has been patched in version b5721.",
  "datePublished": "Jun 24, 2025, 3:21:19 AM",
  "dateUpdated": "Jun 24, 2025, 9:49:53 PM",
  "baseScore": 8.6,
  "baseScoreVersion": "3.1",
  "baseScoreVector": "CVSS:3.1/AV:L/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H",
  "references": [
    "https://github.com/ggml-org/llama.cpp/security/advisories/GHSA-7rxv-5jhh-j6xx",
    "https://github.com/ggml-org/llama.cpp/commit/dd6e6d0b6a4bbe3ebfc931d1eb14db2f2b1d70af"
  ],
  "aliases": [
    "CVE-2025-52566"
  ],
  "assigner": "GitHub_M",
  "epss": 0.05,
  "enisaIdProduct": [
    {
      "id": "1da7b981-9339-3ee2-9873-6009f23f8fe2",
      "product": {
        "name": "llama.cpp"
      },
      "product_version": "< b5721"
    }
  ],
  "enisaIdVendor": [
    {
      "id": "e3ac4450-18aa-3e46-bd19-657a408805a2",
      "vendor": {
        "name": "ggml-org"
      }
    }
  ]
}