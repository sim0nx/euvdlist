{
  "id": "EUVD-2025-7006",
  "enisaUuid": "7ad58107-0358-3122-9ce4-73bfe2daab52",
  "description": "A vulnerability in the LangChainLLM class of the run-llama/llama_index repository, version v0.12.5, allows for a Denial of Service (DoS) attack. The stream_complete method executes the llm using a thread and retrieves the result via the get_response_gen method of the StreamingGeneratorCallbackHandler class. If the thread terminates abnormally before the _llm.predict is executed, there is no exception handling for this case, leading to an infinite loop in the get_response_gen function. This can be triggered by providing an input of an incorrect type, causing the thread to terminate and the process to continue running indefinitely.",
  "datePublished": "Mar 20, 2025, 10:09:06 AM",
  "dateUpdated": "Oct 15, 2025, 12:50:18 PM",
  "baseScore": 7.5,
  "baseScoreVersion": "3.0",
  "baseScoreVector": "CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H",
  "references": [
    "https://nvd.nist.gov/vuln/detail/CVE-2024-12704",
    "https://github.com/run-llama/llama_index/commit/d1ecfb77578d089cbe66728f18f635c09aa32a05",
    "https://huntr.com/bounties/a0b638fd-21c6-4ba7-b381-6ab98472a02a"
  ],
  "aliases": [
    "CVE-2024-12704",
    "GHSA-j3wr-m6xh-64hg"
  ],
  "assigner": "@huntr_ai",
  "epss": 0.23,
  "enisaIdProduct": [
    {
      "id": "6d771a1e-a559-3ff5-974c-2e857b5fcaae",
      "product": {
        "name": "run-llama/llama_index"
      },
      "product_version": "unspecified <0.12.6"
    }
  ],
  "enisaIdVendor": [
    {
      "id": "818837b2-4287-386b-ada7-bb2bd8d5a45f",
      "vendor": {
        "name": "run-llama"
      }
    }
  ]
}